from analyze_bias import analyze_bias_aggregation, save_bias_analysis
from clustering import find_optimal_k, clusterization_result_json
from utils import save_json_with_date, load_config


def main(config_path: str):
    """–û—Å–Ω–æ–≤–Ω–æ–π –ø–∞–π–ø–ª–∞–π–Ω –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ + –∞–Ω–∞–ª–∏–∑ bias."""
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    data = load_config(f'config/{config_path}')

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ k
    n_dms = len(data['dms'])
    safe_k_max = min(8, n_dms - 1)
    safe_k_max = max(2, safe_k_max)
    k = find_optimal_k(data, k_min=1, k_max=safe_k_max)
    print(f"–û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ k: {k}")

    # –í—Å–µ –º–µ—Ç–æ–¥—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
    methods = ['ward', 'kmeans', 'gmm', 'spectral', 'birch', 'dbscan', 'mean_shift']
    final_result = []

    for method in methods:
        print(f"–ó–∞–ø—É—Å–∫ {method}...")
        result = clusterization_result_json(data, n_clusters=k, cluster_method=method)
        final_result.append(result)

    # 1Ô∏è‚É£ –û–°–ù–û–í–ù–û–ô –†–ï–ó–£–õ–¨–¢–ê–¢
    output_file = save_json_with_date(final_result, f"{config_path.replace('.json', '')}_result_clusters")
    print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_file}")

    # 2Ô∏è‚É£ –ê–ù–ê–õ–ò–ó –ò–ó–û–õ–Ø–¶–ò–ò
    print("\nüîç –ê–Ω–∞–ª–∏–∑ –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç–∏ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤...")
    bias_results = analyze_bias_aggregation(final_result)

    bias_filename = f"{config_path.replace('.json', '')}_bias_analysis"
    bias_file = save_bias_analysis(bias_results, bias_filename)
    print(f"üíæ –ê–Ω–∞–ª–∏–∑ bias: {bias_file}")

    # 3Ô∏è‚É£ –¢–û–ü-5 –≤ –∫–æ–Ω—Å–æ–ª—å
    print("\nüèÜ –¢–û–ü-5 –ò–ó–û–õ–ò–†–û–í–ê–ù–ù–´–• –≠–ö–°–ü–ï–†–¢–û–í:")
    print("-" * 40)
    for expert, count in list(bias_results.items())[:5]:
        print(f"{expert}: {count} –º–µ—Ç–æ–¥–æ–≤")


if __name__ == "__main__":
    import os
    files = os.listdir('config')
    print(files)
    for config_path in files:
        main(config_path)
