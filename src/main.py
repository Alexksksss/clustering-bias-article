from analyze_bias import analyze_bias_aggregation, save_bias_analysis
from clustering import find_optimal_k, clusterization_result_json
from utils import save_json_with_date, load_config


def main(config_path: str):
    """ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð¸Ð·Ð°Ñ†Ð¸Ð¸ + Ð°Ð½Ð°Ð»Ð¸Ð· bias."""
    # Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…
    data = load_config(f'config/{config_path}')

    # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ k
    n_dms = len(data['dms'])
    safe_k_max = min(8, n_dms - 1)
    safe_k_max = max(2, safe_k_max)
    k = find_optimal_k(data, k_min=1, k_max=safe_k_max)
    print(f"ÐžÐ¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ k: {k}")

    # Ð’ÑÐµ Ð¼ÐµÑ‚Ð¾Ð´Ñ‹ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð¸Ð·Ð°Ñ†Ð¸Ð¸
    methods = ['ward', 'kmeans', 'gmm', 'spectral', 'birch', 'dbscan', 'mean_shift']
    final_result = []

    for method in methods:
        print(f"Ð—Ð°Ð¿ÑƒÑÐº {method}...")
        result = clusterization_result_json(data, n_clusters=k, cluster_method=method)
        final_result.append(result)

    # 1ï¸âƒ£ ÐžÐ¡ÐÐžÐ’ÐÐžÐ™ Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢
    output_file = save_json_with_date(final_result, f"{config_path.replace('.json', '')}_result_clusters")
    print(f"Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹: {output_file}")

    # 2ï¸âƒ£ ÐÐÐÐ›Ð˜Ð— Ð˜Ð—ÐžÐ›Ð¯Ð¦Ð˜Ð˜
    print("\nðŸ” ÐÐ½Ð°Ð»Ð¸Ð· Ð¿Ñ€ÐµÐ´Ð²Ð·ÑÑ‚Ð¾ÑÑ‚Ð¸ ÑÐºÑÐ¿ÐµÑ€Ñ‚Ð¾Ð²...")
    bias_results = analyze_bias_aggregation(final_result)

    bias_filename = f"{config_path.replace('.json', '')}_bias_analysis"
    bias_file = save_bias_analysis(bias_results, bias_filename)
    print(f"ðŸ’¾ ÐÐ½Ð°Ð»Ð¸Ð· bias: {bias_file}")

    # 3ï¸âƒ£ Ð¢ÐžÐŸ-5 Ð² ÐºÐ¾Ð½ÑÐ¾Ð»ÑŒ
    print("\nðŸ† Ð¢ÐžÐŸ-5 Ð˜Ð—ÐžÐ›Ð˜Ð ÐžÐ’ÐÐÐÐ«Ð¥ Ð­ÐšÐ¡ÐŸÐ•Ð Ð¢ÐžÐ’:")
    print("-" * 40)
    for expert, count in list(bias_results.items())[:5]:
        print(f"{expert}: {count} Ð¼ÐµÑ‚Ð¾Ð´Ð¾Ð²")


if __name__ == "__main__":
    import sys
    config_path = sys.argv[1] if len(sys.argv) > 1 else "data1_from_article.json"
    main(config_path)
